{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing results notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting devices..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # Will use only 1 GPU, please adjust to your GPU config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"..\")\n",
    "from datasets.ssl_dataset import SSL_Dataset\n",
    "from datasets.data_utils import get_data_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from glob import glob\n",
    "from utils import net_builder\n",
    "from train_utils import mcc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSMatch_dir = \"..insert..your..path..here..\"\n",
    "# example:\n",
    "MSMatch_dir = \"/home/roberto/PythonProjects/END2END/MSMatch\"\n",
    "dataset_dir= os.path.join(MSMatch_dir, \"data\")  # \"/home/gabrielemeoni/project/END2END/MSMatch/data/\"\n",
    "test_dset = SSL_Dataset(name=\"thraws_swir_test\", train=False, data_dir=dataset_dir)\n",
    "\n",
    "test_dset_basic = test_dset.get_dset()\n",
    "num_classes = test_dset.num_classes\n",
    "num_channels = test_dset.num_channels\n",
    "eval_loader = get_data_loader(test_dset_basic, 8, num_workers=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoint path..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_paths=[os.path.join(MSMatch_dir, \"checkpoints/\"+x) for x in [\"final_train_supervised\",\"final_train_supervised_no_weights\",\"final_training_msmatch_trained\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking various checkpoints...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_names_list=[]\n",
    "checkpoint_results_list=[]\n",
    "for checkpoint_path in tqdm(checkpoint_paths, desc=\"Checking checkpoint\"):  \n",
    "    checkpoints_names_list.append(checkpoint_path.split(os.sep)[-1])\n",
    "    test_checkpoint_seed_paths=sorted(glob(os.path.join(checkpoint_path, \"*\")))\n",
    "    seeds=[]\n",
    "    test_results_mcc_seed=[]\n",
    "    test_results_acc_seed=[]\n",
    "\n",
    "    for test_seed_path in tqdm(test_checkpoint_seed_paths, desc=\"Processing seed...\"):\n",
    "        seeds.append(int(test_seed_path.split(os.sep)[-1].split(\"_\")[-1]))\n",
    "        upsampling_values_test_paths=sorted(glob(os.path.join(test_seed_path, \"*\")))\n",
    "        test_results_acc_seed_upsample=[]\n",
    "        test_results_mcc_seed_upsample=[]\n",
    "        upsampling_values=[]\n",
    "        for test in upsampling_values_test_paths:\n",
    "            upsampling_values.append(int(test.split(\"_{\")[1].split(\"}\")[0]))\n",
    "\n",
    "            #Exploring the whole path until you reach the final directory\n",
    "            while(len(glob(os.path.join(test, \"*\"))) == 1):\n",
    "                test=os.path.join(test, glob(os.path.join(test, \"*\"))[0])\n",
    "\n",
    "            checkpoint_path = os.path.join(test, \"model_best.pth\")\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            load_model = (checkpoint[\"eval_model\"])\n",
    "\n",
    "            _net_builder = net_builder(\n",
    "                \"efficientnet-lite0\",\n",
    "                False,\n",
    "                {\n",
    "                    \"depth\": 28,\n",
    "                    \"widen_factor\": 2,\n",
    "                    \"leaky_slope\": 0.1,\n",
    "                    \"dropRate\": 0.0,\n",
    "                },\n",
    "            )\n",
    "            net = _net_builder(num_classes=num_classes, in_channels=num_channels)\n",
    "            net.load_state_dict(load_model)\n",
    "            if torch.cuda.is_available():\n",
    "                net.cuda()\n",
    "            net.eval()\n",
    "\n",
    "            acc = 0.0\n",
    "            y_true=[]\n",
    "            y_pred=[]\n",
    "            n=0\n",
    "            with torch.no_grad():\n",
    "                for image, target in eval_loader:\n",
    "                    image = image.type(torch.FloatTensor).cuda()\n",
    "                    logit = net(image)\n",
    "                    y_pred+=list(logit.cpu().max(1)[1])\n",
    "                    y_true+=list(target)\n",
    "                    acc += logit.cpu().max(1)[1].eq(target).sum().numpy()\n",
    "\n",
    "                    if n == 0:\n",
    "                            pred=logit\n",
    "                            correct=target\n",
    "                            n+=1\n",
    "                    else:\n",
    "                        pred=torch.cat((pred, logit), axis=0)\n",
    "                        correct=torch.cat((correct, target), axis=0)\n",
    "            test_results_acc_seed_upsample.append(acc / len(test_dset_basic))\n",
    "            test_results_mcc_seed_upsample.append(mcc(pred, correct))\n",
    "\n",
    "        upsampling_values=[\"up_\" + str(upsampling_value) for upsampling_value in upsampling_values]\n",
    "        print(upsampling_values)\n",
    "        test_results_acc_seed.append(dict(zip(upsampling_values, test_results_acc_seed_upsample)))\n",
    "        test_results_mcc_seed.append(dict(zip(upsampling_values, test_results_mcc_seed_upsample)))\n",
    "\n",
    "    seeds_sorted_idx=sorted(range(len(seeds)),key=seeds.__getitem__)\n",
    "    seeds_sorted=[\"seed_\"+str(seeds[n]) for n in seeds_sorted_idx]\n",
    "    test_results_acc_seed_sorted=[test_results_acc_seed[n] for n in seeds_sorted_idx]\n",
    "    test_results_mcc_seed_sorted=[test_results_mcc_seed[n] for n in seeds_sorted_idx]\n",
    "\n",
    "    tests_results_acc_dict=dict(zip(seeds_sorted, test_results_acc_seed_sorted))\n",
    "    tests_results_mcc_dict=dict(zip(seeds_sorted, test_results_mcc_seed_sorted))\n",
    "    checkpoint_results_list.append({\"acc\" : tests_results_acc_dict, \"mcc\" : tests_results_mcc_dict})\n",
    "checkpoints_results_dict=dict(zip(checkpoints_names_list, checkpoint_results_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised training (weighted) results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_supervised_weighted=pd.DataFrame.from_dict(checkpoints_results_dict[\"final_train_supervised\"][\"acc\"], orient='index',columns=upsampling_values)\n",
    "acc_df_supervised_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCC results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_df_supervised_weighted=pd.DataFrame.from_dict(checkpoints_results_dict[\"final_train_supervised\"][\"mcc\"], orient='index',columns=upsampling_values)\n",
    "mcc_df_supervised_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised training un-weighted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_supervised_no_weighted=pd.DataFrame.from_dict(checkpoints_results_dict[\"final_train_supervised_no_weights\"][\"acc\"], orient='index',columns=upsampling_values)\n",
    "acc_df_supervised_no_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCC results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_df_supervised_no_weighted=pd.DataFrame.from_dict(checkpoints_results_dict[\"final_train_supervised_no_weights\"][\"mcc\"], orient='index',columns=upsampling_values)\n",
    "mcc_df_supervised_no_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_best_df=pd.DataFrame.copy(acc_df_supervised_no_weighted)\n",
    "mcc_best_df=pd.DataFrame.copy(mcc_df_supervised_no_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in [\"up_2\", \"up_3\", \"up_4\", \"up_6\", \"up_7\"]:\n",
    "    for seed in [\"seed_0\", \"seed_9\", \"seed_14\", \"seed_18\", \"seed_19\"]:\n",
    "        acc_best_df.loc[seed][key]=max(acc_df_supervised_no_weighted.loc[seed][key], acc_df_supervised_weighted.loc[seed][key])\n",
    "        mcc_best_df.loc[seed][key]=max(mcc_df_supervised_no_weighted.loc[seed][key], mcc_df_supervised_weighted.loc[seed][key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_mean=acc_best_df.iloc[:-1].mean(axis=0)\n",
    "pd.DataFrame(dict(zip(list(best_acc_mean.keys().values), list(best_acc_mean.values))), index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best MCC results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mcc_mean=mcc_best_df.iloc[:-1].mean(axis=0)\n",
    "pd.DataFrame(dict(zip(list(best_mcc_mean.keys().values), list(best_mcc_mean.values))), index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSMatch results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_msmatch_weighted=pd.DataFrame.from_dict(checkpoints_results_dict[\"final_training_msmatch_trained\"][\"acc\"], orient='index',columns=upsampling_values)\n",
    "acc_df_msmatch_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCC results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_df_msmatch_weighted=pd.DataFrame.from_dict(checkpoints_results_dict[\"final_training_msmatch_trained\"][\"mcc\"], orient='index',columns=upsampling_values)\n",
    "mcc_df_msmatch_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_df_msmatch_weighted_mean=mcc_df_msmatch_weighted.iloc[:-1].mean(axis=0)\n",
    "pd.DataFrame(dict(zip(list(mcc_df_msmatch_weighted_mean.keys().values), list(mcc_df_msmatch_weighted_mean.values))), index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking missclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking missclassifications for the model having the best MCC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path=\"/home/gabrielemeoni/project/END2END/MSMatch/checkpoints/final_train_supervised/Seed_14/hyperExplore_upsTrain_{7}_upsEval_{1}/thraws_swir_train/FixMatch_archefficientnet-lite0_batch8_confidence0.95_lr0.03_uratio4_wd0.00075_wu1.0_seed14_numlabels800_optSGD/model_best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing batch to 1\n",
    "eval_loader = get_data_loader(test_dset_basic, 1, num_workers=1)\n",
    "checkpoint = torch.load(best_model_path)\n",
    "load_model = (checkpoint[\"eval_model\"])\n",
    "\n",
    "_net_builder = net_builder(\n",
    "    \"efficientnet-lite0\",\n",
    "    False,\n",
    "    {\n",
    "        \"depth\": 28,\n",
    "        \"widen_factor\": 2,\n",
    "        \"leaky_slope\": 0.1,\n",
    "        \"dropRate\": 0.0,\n",
    "    },\n",
    ")\n",
    "net = _net_builder(num_classes=num_classes, in_channels=num_channels)\n",
    "net.load_state_dict(load_model)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net.eval()\n",
    "\n",
    "y_true=[]\n",
    "y_pred=[]\n",
    "x_wrong=[]\n",
    "with torch.no_grad():\n",
    "    for image, target in tqdm(eval_loader, desc=\"Checking best model...\"):\n",
    "        image = image.type(torch.FloatTensor).cuda()\n",
    "        logit = net(image)\n",
    "        \n",
    "        if (logit.cpu().max(1)[1] != target):\n",
    "            x_wrong.append(image)\n",
    "            y_pred+=list(logit.cpu().max(1)[1])\n",
    "            y_true+=list(target)\n",
    "\n",
    "        if n == 0:\n",
    "                pred=logit\n",
    "                correct=target\n",
    "                n+=1\n",
    "        else:\n",
    "            pred=torch.cat((pred, logit), axis=0)\n",
    "            correct=torch.cat((correct, target), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax=plt.subplots(2,3, figsize=(20, 20))\n",
    "event_dict={\"0\" : \"event\", \"1\" : \"not_event\"}\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "for n, x in enumerate(x_wrong):\n",
    "    x=np.transpose(x.squeeze(0).detach().cuda().cpu().numpy(), (2,1,0))\n",
    "    ax[int(n/3), int(n%3)].imshow(x/x.max())\n",
    "    ax[int(n/3), int(n%3)].set_title(\"predicted: \"+str(event_dict[str(int(y_pred[n]))])+\"\\ntrue: \"+str(event_dict[str(int(y_true[n]))]))\n",
    "    ax[int(n/3), int(n%3)].tick_params(left = False, right = False , labelleft = False , labelbottom = False, bottom = False)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end2end",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
